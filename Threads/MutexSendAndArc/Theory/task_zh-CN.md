## 锁、`Send` 和 `Arc`

您刚刚实现的补丁策略有一个重大缺点：它是有竞争条件的。  
如果两个客户端几乎同时为同一个工单发送补丁，服务器将以任意顺序应用它们。  
最后一个排队的补丁将覆盖另一客户端所做的更改。

## 版本号

我们可以尝试通过使用**版本号**来解决这个问题。  
每个工单在创建时都会被分配一个版本号，初始值为 `0`。  
每当客户端发送补丁时，必须包括该工单当前的版本号以及所需的更改。服务器仅在版本号与其存储的匹配时才会应用补丁。

在上述场景中，服务器将拒绝第二个补丁，因为版本号已经被第一个补丁递增，因此不会与第二个客户端发送的版本号匹配。

这种方法在分布式系统中非常常见（例如，当客户端和服务器不共享内存时），这被称为**乐观并发控制**。  
其思想是，大多数情况下冲突不会发生，因此我们可以针对常见情况进行优化。  
如果您愿意，可以尝试使用您现在对 Rust 的了解自行实现这个策略，作为一个额外练习。

## 锁定

我们还可以通过引入**锁**来修复竞争条件。  
每当一个客户端想要更新工单时，他们必须首先为其获取一个锁。在锁激活期间，其他客户端无法修改工单。

Rust 的标准库提供了两种不同的锁定原语：`Mutex<T>` 和 `RwLock<T>`。  
让我们从 `Mutex<T>` 开始。它代表**互**斥锁（**mut**ual **ex**clusion），是最简单的一种锁：  
它不论用于读还是写，都仅允许一个线程访问数据。

`Mutex<T>` 包裹了它保护的数据，因此它对数据类型是泛型的。  
您不能直接访问这些数据：类型系统强制您首先通过 `Mutex::lock` 或 `Mutex::try_lock` 获取锁。前者会阻塞直到锁被获取，后者如果无法获取锁则立即返回错误。  
两种方法都会返回一个守护对象，该对象可以解引用为数据，从而允许您修改数据。锁将在守护对象被丢弃时释放。

```rust
use std::sync::Mutex;

// 被互斥锁保护的整数
let lock = Mutex::new(0);

// 获取互斥锁
let mut guard = lock.lock().unwrap();

// 通过守护对象修改数据，
// 利用其 `Deref` 实现
*guard += 1;

// 当 `data` 超出作用域时，锁会被释放。
// 可以通过显式丢弃守护或者
// 隐式地让守护超出作用域来完成
drop(guard)
```

## 锁定粒度

我们的 `Mutex` 应该包裹什么？  
最简单的选择是用一个单一的 `Mutex` 包裹整个 `TicketStore`。  
这可以工作，但会严重限制系统性能：您不能并行读取工单，因为每次读取都需要等待锁释放。  
这就是所谓的**粗粒度锁定**。

更好的方法是使用**细粒度锁定**，为每个工单单独设置一个锁。  
这样，只要它们不试图访问同一个工单，客户端就可以并行处理工单。

```rust
// 新结构，每个工单都有一个锁
struct TicketStore {
    tickets: BTreeMap<TicketId, Mutex<Ticket>>,
}
```

这种方法更高效，但存在一个缺点：`TicketStore` 必须对系统的